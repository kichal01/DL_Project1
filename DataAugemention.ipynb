{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252236f3-2a54-49fd-8648-3603e9261c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision.transforms import v2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dea2dcd-cc77-4eb0-a9a5-d56a263d48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e6b4c-bd78-4a84-873d-ae63e8e193ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632b2601-5e66-4376-ae04-38c2423d0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "set_seed()\n",
    "\n",
    "train_set = ImageFolder(root='cinic10/versions/1/train//', transform=transform)\n",
    "validate_set = ImageFolder(root='cinic10/versions/1/valid//', transform=transform)\n",
    "test_set = ImageFolder(root='cinic10/versions/1/test//', transform=transform)\n",
    "\n",
    "class_names = train_set.classes\n",
    "num_labels = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d21e52-f7e5-4b72-b120-23f665fd8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models import resnext50_32x4d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e668e2-f408-4919-b594-cc289a37b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_efficient_net(lr):\n",
    "    model = efficientnet_b0(pretrained=False)\n",
    "    model.classifier[1] = nn.Linear(in_features=1280, out_features=num_labels, bias=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a118c57-02ea-48cd-8a1e-d6735aae4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_transforms(transform_train, transform_test):\n",
    "    \n",
    "    train_set = ImageFolder(root='cinic10/versions/1/train//', transform=transform_train)\n",
    "    validate_set = ImageFolder(root='cinic10/versions/1/valid//', transform=transform_test)\n",
    "    test_set = ImageFolder(root='cinic10/versions/1/test//', transform=transform_test)\n",
    "        \n",
    "    data_loader = DataLoader(train_set, batch_size=128, num_workers=6, generator=torch.Generator(device='cpu'),pin_memory=True, shuffle=True,persistent_workers=True, prefetch_factor=4)\n",
    "    data_loader_val = DataLoader(validate_set, batch_size=128, num_workers=6, generator=torch.Generator(device='cpu'),pin_memory=True, shuffle=True,persistent_workers=True, prefetch_factor=4)\n",
    "    data_loader_test = DataLoader(test_set, batch_size=64, num_workers=4, generator=torch.Generator(device='cpu'),persistent_workers=True)\n",
    "\n",
    "    return data_loader, data_loader_val, data_loader_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac5896b-89a1-45f9-9b5a-2db4b126e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_default = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transform_rotations = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees = (-30,30)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_scaling = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size = (32,32),scale=(0.8, 1.0)),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_greyscale = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "transform_random_40 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "        transforms.RandomApply(torch.nn.ModuleList([\n",
    "     transforms.RandomRotation(degrees = (-30,30)),\n",
    " ]), p=0.4),\n",
    "    transforms.RandomApply(torch.nn.ModuleList([\n",
    "     transforms.RandomResizedCrop(size = (32,32),scale=(0.8, 1.0)),\n",
    " ]), p=0.4)])\n",
    "\n",
    "transform_random_80 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "        transforms.RandomApply(torch.nn.ModuleList([\n",
    "     transforms.RandomRotation(degrees = (-30,30)),\n",
    " ]), p=0.8),\n",
    "    transforms.RandomApply(torch.nn.ModuleList([\n",
    "     transforms.RandomResizedCrop(size = (32,32),scale=(0.8, 1.0)),\n",
    " ]), p=0.8)])\n",
    "\n",
    "\n",
    "transform_scaling_rotating = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size = (32,32),scale=(0.8, 1.0)),  \n",
    "    transforms.RandomRotation(degrees = (-30,30)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#cutmix = v2.CutMix(num_classes=num_labels)\n",
    "\n",
    "\n",
    "\n",
    "transforms_list = [transform_default,\n",
    "                  transform_rotations,\n",
    "                  transform_scaling,\n",
    "                  transform_greyscale,\n",
    "                  transform_random_40,\n",
    "                  transform_random_80,\n",
    "                  transform_scaling_rotating]\n",
    "\n",
    "transforms_test = [transform_default,\n",
    "                   transform_default,\n",
    "                   transform_default,\n",
    "                   transform_greyscale,\n",
    "                   transform_default,\n",
    "                   transform_default,\n",
    "                   transform_default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bffb7e6-1686-4207-b850-438d1c0f5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(lr,transforms_list, test_list,prepare_model, seed):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "    losses_tr = []\n",
    "    accuracies_tr = []\n",
    "    losses_val = []\n",
    "    accuracies_val = []\n",
    "    \n",
    "    for transform, transform_test in zip(transforms_list, test_list):\n",
    "        data_loader, data_loader_val, data_loader_test = prepare_transforms(transform, transform_test)\n",
    "        print('transform: '+ str(transform)+ ' test_transform: '+ str(transform_test))\n",
    "    \n",
    "        model, optimizer, criterion = prepare_model(lr)\n",
    "        \n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        num_epochs = 12\n",
    "        \n",
    "        prev_prev_loss = float('inf')\n",
    "        prev_loss = float('inf')\n",
    "        curr_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(num_epochs): \n",
    "            print('Entered the loop')\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i, (batch_X, batch_Y) in enumerate(data_loader):\n",
    "                X = batch_X.to(device, non_blocking=True)  \n",
    "                if(i == 1):\n",
    "                    print('going')\n",
    "                Y = batch_Y.to(device, non_blocking=True)  \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == Y).sum().item()\n",
    "                total += Y.size(0)\n",
    "            \n",
    "\n",
    "            avg_loss = total_loss / len(data_loader)\n",
    "            train_accuracy = correct / total * 100\n",
    "            train_losses.append(avg_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_Y in data_loader_val:\n",
    "                    X = batch_X.to(device, non_blocking=True)\n",
    "                    Y = batch_Y.to(device, non_blocking=True)\n",
    "                    outputs = model(X)\n",
    "                    loss = criterion(outputs, Y)\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct += (predicted == Y).sum().item()\n",
    "                    total += Y.size(0)\n",
    "            avg_val_loss = val_loss / len(data_loader_val)\n",
    "            val_accuracy = correct / total * 100\n",
    "            print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "            \n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    \n",
    "            if(avg_val_loss>curr_loss and curr_loss>prev_loss and prev_loss > prev_prev_loss):\n",
    "                losses_tr.append(train_losses)\n",
    "                accuracies_tr.append(train_accuracies) \n",
    "                losses_val.append(val_losses)  \n",
    "                accuracies_val.append(val_accuracies) \n",
    "                break\n",
    "            prev_prev_loss = prev_loss\n",
    "            prev_loss = curr_loss\n",
    "            curr_loss = avg_val_loss\n",
    "        \n",
    "            if(epoch == num_epochs - 1 ):\n",
    "                losses_tr.append(train_losses)\n",
    "                accuracies_tr.append(train_accuracies) \n",
    "                losses_val.append(val_losses)  \n",
    "                accuracies_val.append(val_accuracies) \n",
    "    return losses_tr, accuracies_tr, losses_val, accuracies_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4462043f-0485-4909-abcf-4dc7160d3e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform: Compose(\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.8964\n",
      "Epoch 1, Validation Loss: 1.7583, Accuracy: 36.44%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.5984\n",
      "Epoch 2, Validation Loss: 1.4898, Accuracy: 45.37%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.4447\n",
      "Epoch 3, Validation Loss: 1.4325, Accuracy: 47.85%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.3392\n",
      "Epoch 4, Validation Loss: 1.3124, Accuracy: 52.66%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.2503\n",
      "Epoch 5, Validation Loss: 1.4698, Accuracy: 47.10%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.2847\n",
      "Epoch 6, Validation Loss: 1.2562, Accuracy: 55.05%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.1661\n",
      "Epoch 7, Validation Loss: 1.1980, Accuracy: 56.72%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.1227\n",
      "Epoch 8, Validation Loss: 1.1613, Accuracy: 58.01%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.0766\n",
      "Epoch 9, Validation Loss: 1.1644, Accuracy: 58.07%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.0803\n",
      "Epoch 10, Validation Loss: 1.1305, Accuracy: 59.63%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.0993\n",
      "Epoch 11, Validation Loss: 1.1272, Accuracy: 59.65%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.0523\n",
      "Epoch 12, Validation Loss: 1.3749, Accuracy: 50.82%\n",
      "transform: Compose(\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9239\n",
      "Epoch 1, Validation Loss: 1.7645, Accuracy: 36.35%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6821\n",
      "Epoch 2, Validation Loss: 1.6901, Accuracy: 42.04%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5478\n",
      "Epoch 3, Validation Loss: 1.4499, Accuracy: 46.95%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4814\n",
      "Epoch 4, Validation Loss: 1.3711, Accuracy: 49.70%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3951\n",
      "Epoch 5, Validation Loss: 1.3333, Accuracy: 51.26%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.3410\n",
      "Epoch 6, Validation Loss: 1.2786, Accuracy: 53.35%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3013\n",
      "Epoch 7, Validation Loss: 1.3943, Accuracy: 51.61%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.2588\n",
      "Epoch 8, Validation Loss: 1.2126, Accuracy: 55.54%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.2427\n",
      "Epoch 9, Validation Loss: 1.1829, Accuracy: 57.52%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2116\n",
      "Epoch 10, Validation Loss: 1.1652, Accuracy: 58.10%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2296\n",
      "Epoch 11, Validation Loss: 1.1363, Accuracy: 59.34%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.3420\n",
      "Epoch 12, Validation Loss: 1.2144, Accuracy: 56.04%\n",
      "transform: Compose(\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9200\n",
      "Epoch 1, Validation Loss: 1.8947, Accuracy: 33.86%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6549\n",
      "Epoch 2, Validation Loss: 1.7334, Accuracy: 41.81%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5299\n",
      "Epoch 3, Validation Loss: 1.5538, Accuracy: 46.26%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4253\n",
      "Epoch 4, Validation Loss: 1.6132, Accuracy: 48.14%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3348\n",
      "Epoch 5, Validation Loss: 1.2922, Accuracy: 53.31%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.2687\n",
      "Epoch 6, Validation Loss: 1.2410, Accuracy: 55.70%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.2099\n",
      "Epoch 7, Validation Loss: 1.2413, Accuracy: 56.05%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.1596\n",
      "Epoch 8, Validation Loss: 1.1635, Accuracy: 58.52%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.1191\n",
      "Epoch 9, Validation Loss: 1.1406, Accuracy: 59.26%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.0982\n",
      "Epoch 10, Validation Loss: 1.1018, Accuracy: 61.18%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.0716\n",
      "Epoch 11, Validation Loss: 1.0828, Accuracy: 61.73%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.0283\n",
      "Epoch 12, Validation Loss: 1.0386, Accuracy: 63.18%\n",
      "transform: Compose(\n",
      "    Grayscale(num_output_channels=3)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    Grayscale(num_output_channels=3)\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 2.0197\n",
      "Epoch 1, Validation Loss: 2.0493, Accuracy: 29.45%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.7405\n",
      "Epoch 2, Validation Loss: 1.6137, Accuracy: 40.84%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5497\n",
      "Epoch 3, Validation Loss: 1.5220, Accuracy: 44.76%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4312\n",
      "Epoch 4, Validation Loss: 1.9144, Accuracy: 33.07%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3593\n",
      "Epoch 5, Validation Loss: 1.3690, Accuracy: 50.77%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.3115\n",
      "Epoch 6, Validation Loss: 1.4462, Accuracy: 48.15%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.2451\n",
      "Epoch 7, Validation Loss: 1.4380, Accuracy: 49.02%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.2020\n",
      "Epoch 8, Validation Loss: 1.5421, Accuracy: 43.05%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.1672\n",
      "Epoch 9, Validation Loss: 1.2397, Accuracy: 55.83%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.0942\n",
      "Epoch 10, Validation Loss: 1.2240, Accuracy: 56.63%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.0645\n",
      "Epoch 11, Validation Loss: 1.3025, Accuracy: 53.97%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.0244\n",
      "Epoch 12, Validation Loss: 1.1885, Accuracy: 57.73%\n",
      "transform: Compose(\n",
      "    ToTensor()\n",
      "    RandomApply(\n",
      "    p=0.4\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      ")\n",
      "    RandomApply(\n",
      "    p=0.4\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      ")\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9376\n",
      "Epoch 1, Validation Loss: 1.7861, Accuracy: 32.84%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6984\n",
      "Epoch 2, Validation Loss: 1.5986, Accuracy: 42.91%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5450\n",
      "Epoch 3, Validation Loss: 1.4777, Accuracy: 45.71%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4828\n",
      "Epoch 4, Validation Loss: 1.4072, Accuracy: 48.71%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3884\n",
      "Epoch 5, Validation Loss: 1.2939, Accuracy: 53.18%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.3625\n",
      "Epoch 6, Validation Loss: 1.3662, Accuracy: 50.52%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3124\n",
      "Epoch 7, Validation Loss: 1.3066, Accuracy: 52.34%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.2669\n",
      "Epoch 8, Validation Loss: 1.2410, Accuracy: 55.45%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.3112\n",
      "Epoch 9, Validation Loss: 1.1846, Accuracy: 57.50%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2677\n",
      "Epoch 10, Validation Loss: 1.1593, Accuracy: 58.38%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.1801\n",
      "Epoch 11, Validation Loss: 1.1524, Accuracy: 58.56%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.1496\n",
      "Epoch 12, Validation Loss: 1.0845, Accuracy: 61.16%\n",
      "transform: Compose(\n",
      "    ToTensor()\n",
      "    RandomApply(\n",
      "    p=0.8\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      ")\n",
      "    RandomApply(\n",
      "    p=0.8\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      ")\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9651\n",
      "Epoch 1, Validation Loss: 1.7710, Accuracy: 33.27%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.7149\n",
      "Epoch 2, Validation Loss: 1.6040, Accuracy: 42.10%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.6033\n",
      "Epoch 3, Validation Loss: 1.5266, Accuracy: 43.67%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.5165\n",
      "Epoch 4, Validation Loss: 1.4277, Accuracy: 48.07%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.4481\n",
      "Epoch 5, Validation Loss: 1.3278, Accuracy: 51.48%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.4203\n",
      "Epoch 6, Validation Loss: 1.3170, Accuracy: 52.92%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3549\n",
      "Epoch 7, Validation Loss: 1.2715, Accuracy: 53.98%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.3098\n",
      "Epoch 8, Validation Loss: 1.2850, Accuracy: 53.71%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.2796\n",
      "Epoch 9, Validation Loss: 1.2292, Accuracy: 55.67%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2408\n",
      "Epoch 10, Validation Loss: 1.1645, Accuracy: 58.03%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2130\n",
      "Epoch 11, Validation Loss: 1.1355, Accuracy: 59.20%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.1847\n",
      "Epoch 12, Validation Loss: 1.3234, Accuracy: 55.40%\n",
      "transform: Compose(\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9462\n",
      "Epoch 1, Validation Loss: 1.7699, Accuracy: 34.18%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.7214\n",
      "Epoch 2, Validation Loss: 1.5875, Accuracy: 41.28%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.6113\n",
      "Epoch 3, Validation Loss: 1.5306, Accuracy: 44.34%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.5381\n",
      "Epoch 4, Validation Loss: 1.4856, Accuracy: 46.28%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.4713\n",
      "Epoch 5, Validation Loss: 1.4138, Accuracy: 49.12%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.4239\n",
      "Epoch 6, Validation Loss: 1.4220, Accuracy: 50.62%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3754\n",
      "Epoch 7, Validation Loss: 1.2838, Accuracy: 53.26%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.3564\n",
      "Epoch 8, Validation Loss: 1.3606, Accuracy: 52.43%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.3591\n",
      "Epoch 9, Validation Loss: 1.2683, Accuracy: 53.72%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.3054\n",
      "Epoch 10, Validation Loss: 1.2184, Accuracy: 56.24%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2719\n",
      "Epoch 11, Validation Loss: 1.1690, Accuracy: 57.79%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.2288\n",
      "Epoch 12, Validation Loss: 1.1847, Accuracy: 58.28%\n",
      "transform: Compose(\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9029\n",
      "Epoch 1, Validation Loss: 1.7396, Accuracy: 35.92%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6160\n",
      "Epoch 2, Validation Loss: 1.5445, Accuracy: 43.33%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.4550\n",
      "Epoch 3, Validation Loss: 1.5111, Accuracy: 47.36%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.3514\n",
      "Epoch 4, Validation Loss: 1.3574, Accuracy: 50.69%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.2668\n",
      "Epoch 5, Validation Loss: 1.3170, Accuracy: 52.21%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.2101\n",
      "Epoch 6, Validation Loss: 1.2599, Accuracy: 53.79%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.1541\n",
      "Epoch 7, Validation Loss: 1.2959, Accuracy: 52.73%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.1025\n",
      "Epoch 8, Validation Loss: 1.1522, Accuracy: 58.50%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.0413\n",
      "Epoch 9, Validation Loss: 1.1383, Accuracy: 58.96%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.0031\n",
      "Epoch 10, Validation Loss: 1.1360, Accuracy: 59.27%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 0.9653\n",
      "Epoch 11, Validation Loss: 1.0865, Accuracy: 61.06%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 0.9281\n",
      "Epoch 12, Validation Loss: 1.1180, Accuracy: 60.14%\n",
      "transform: Compose(\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9469\n",
      "Epoch 1, Validation Loss: 1.9132, Accuracy: 32.13%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6897\n",
      "Epoch 2, Validation Loss: 1.6119, Accuracy: 40.32%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.6070\n",
      "Epoch 3, Validation Loss: 1.5754, Accuracy: 41.85%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.5193\n",
      "Epoch 4, Validation Loss: 1.4741, Accuracy: 46.03%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.4457\n",
      "Epoch 5, Validation Loss: 1.3906, Accuracy: 48.92%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.4000\n",
      "Epoch 6, Validation Loss: 1.3514, Accuracy: 51.31%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3961\n",
      "Epoch 7, Validation Loss: 1.3432, Accuracy: 50.85%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.3940\n",
      "Epoch 8, Validation Loss: 1.2626, Accuracy: 54.16%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.3177\n",
      "Epoch 9, Validation Loss: 1.2843, Accuracy: 53.40%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2679\n",
      "Epoch 10, Validation Loss: 1.2155, Accuracy: 56.35%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2719\n",
      "Epoch 11, Validation Loss: 1.2605, Accuracy: 54.87%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.3347\n",
      "Epoch 12, Validation Loss: 1.4002, Accuracy: 49.71%\n",
      "transform: Compose(\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.8877\n",
      "Epoch 1, Validation Loss: 1.6857, Accuracy: 37.49%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6064\n",
      "Epoch 2, Validation Loss: 1.5502, Accuracy: 43.40%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.4876\n",
      "Epoch 3, Validation Loss: 1.4801, Accuracy: 46.86%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4015\n",
      "Epoch 4, Validation Loss: 1.3885, Accuracy: 49.12%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3266\n",
      "Epoch 5, Validation Loss: 1.3809, Accuracy: 52.82%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.2670\n",
      "Epoch 6, Validation Loss: 1.2233, Accuracy: 55.77%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.2204\n",
      "Epoch 7, Validation Loss: 1.5432, Accuracy: 45.30%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.3059\n",
      "Epoch 8, Validation Loss: 1.2385, Accuracy: 55.51%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.1714\n",
      "Epoch 9, Validation Loss: 1.2021, Accuracy: 56.98%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.1280\n",
      "Epoch 10, Validation Loss: 1.1135, Accuracy: 60.17%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.0898\n",
      "Epoch 11, Validation Loss: 1.1011, Accuracy: 60.61%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.0572\n",
      "Epoch 12, Validation Loss: 1.0887, Accuracy: 61.08%\n",
      "transform: Compose(\n",
      "    Grayscale(num_output_channels=3)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    Grayscale(num_output_channels=3)\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 2.0282\n",
      "Epoch 1, Validation Loss: 1.8340, Accuracy: 31.99%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.7040\n",
      "Epoch 2, Validation Loss: 1.6463, Accuracy: 39.70%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5318\n",
      "Epoch 3, Validation Loss: 1.5209, Accuracy: 44.81%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.3973\n",
      "Epoch 4, Validation Loss: 1.4158, Accuracy: 48.84%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3148\n",
      "Epoch 5, Validation Loss: 1.3794, Accuracy: 50.38%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.2430\n",
      "Epoch 6, Validation Loss: 1.3501, Accuracy: 51.94%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.1924\n",
      "Epoch 7, Validation Loss: 1.3599, Accuracy: 51.64%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.1453\n",
      "Epoch 8, Validation Loss: 1.2413, Accuracy: 55.78%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.0960\n",
      "Epoch 9, Validation Loss: 1.2791, Accuracy: 54.84%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.0718\n",
      "Epoch 10, Validation Loss: 1.1937, Accuracy: 57.76%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.0221\n",
      "Epoch 11, Validation Loss: 1.2539, Accuracy: 56.34%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.0143\n",
      "Epoch 12, Validation Loss: 1.1757, Accuracy: 58.76%\n",
      "transform: Compose(\n",
      "    ToTensor()\n",
      "    RandomApply(\n",
      "    p=0.4\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      ")\n",
      "    RandomApply(\n",
      "    p=0.4\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      ")\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9449\n",
      "Epoch 1, Validation Loss: 2.0719, Accuracy: 34.94%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6871\n",
      "Epoch 2, Validation Loss: 1.6066, Accuracy: 42.35%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5541\n",
      "Epoch 3, Validation Loss: 1.6225, Accuracy: 41.97%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4575\n",
      "Epoch 4, Validation Loss: 1.4642, Accuracy: 48.28%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3846\n",
      "Epoch 5, Validation Loss: 1.3117, Accuracy: 52.52%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.3294\n",
      "Epoch 6, Validation Loss: 1.2349, Accuracy: 55.93%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.2726\n",
      "Epoch 7, Validation Loss: 1.2431, Accuracy: 55.70%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.2710\n",
      "Epoch 8, Validation Loss: 1.2197, Accuracy: 55.74%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.2266\n",
      "Epoch 9, Validation Loss: 1.2736, Accuracy: 57.60%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.1728\n",
      "Epoch 10, Validation Loss: 1.1267, Accuracy: 59.89%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.1763\n",
      "Epoch 11, Validation Loss: 1.1674, Accuracy: 58.04%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.1429\n",
      "Epoch 12, Validation Loss: 1.0933, Accuracy: 60.99%\n",
      "transform: Compose(\n",
      "    ToTensor()\n",
      "    RandomApply(\n",
      "    p=0.8\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      ")\n",
      "    RandomApply(\n",
      "    p=0.8\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      ")\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 2.0060\n",
      "Epoch 1, Validation Loss: 1.8237, Accuracy: 31.18%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.7711\n",
      "Epoch 2, Validation Loss: 1.7549, Accuracy: 35.36%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.6480\n",
      "Epoch 3, Validation Loss: 1.5556, Accuracy: 41.86%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.5981\n",
      "Epoch 4, Validation Loss: 1.5095, Accuracy: 44.28%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.5136\n",
      "Epoch 5, Validation Loss: 1.4936, Accuracy: 45.71%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.4603\n",
      "Epoch 6, Validation Loss: 1.3274, Accuracy: 51.78%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.4033\n",
      "Epoch 7, Validation Loss: 1.3419, Accuracy: 50.66%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.3645\n",
      "Epoch 8, Validation Loss: 1.2876, Accuracy: 52.92%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.3214\n",
      "Epoch 9, Validation Loss: 1.2622, Accuracy: 53.73%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2801\n",
      "Epoch 10, Validation Loss: 1.1931, Accuracy: 57.18%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2524\n",
      "Epoch 11, Validation Loss: 1.1748, Accuracy: 57.61%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.2286\n",
      "Epoch 12, Validation Loss: 1.1840, Accuracy: 57.56%\n",
      "transform: Compose(\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9377\n",
      "Epoch 1, Validation Loss: 1.7828, Accuracy: 34.37%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6960\n",
      "Epoch 2, Validation Loss: 1.6054, Accuracy: 40.88%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.6070\n",
      "Epoch 3, Validation Loss: 1.4842, Accuracy: 45.98%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.5263\n",
      "Epoch 4, Validation Loss: 1.5617, Accuracy: 45.18%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.4592\n",
      "Epoch 5, Validation Loss: 1.3719, Accuracy: 49.90%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.4559\n",
      "Epoch 6, Validation Loss: 1.4292, Accuracy: 49.67%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3871\n",
      "Epoch 7, Validation Loss: 1.3075, Accuracy: 52.23%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.3394\n",
      "Epoch 8, Validation Loss: 1.3352, Accuracy: 51.84%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.3195\n",
      "Epoch 9, Validation Loss: 1.3265, Accuracy: 52.27%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2861\n",
      "Epoch 10, Validation Loss: 1.2890, Accuracy: 53.40%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2644\n",
      "Epoch 11, Validation Loss: 1.1952, Accuracy: 57.06%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.2314\n",
      "Epoch 12, Validation Loss: 1.1653, Accuracy: 57.98%\n",
      "transform: Compose(\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9031\n",
      "Epoch 1, Validation Loss: 1.6832, Accuracy: 36.74%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6057\n",
      "Epoch 2, Validation Loss: 1.5348, Accuracy: 44.14%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.4656\n",
      "Epoch 3, Validation Loss: 1.4370, Accuracy: 47.71%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.3573\n",
      "Epoch 4, Validation Loss: 1.3412, Accuracy: 50.76%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.2677\n",
      "Epoch 5, Validation Loss: 1.2959, Accuracy: 53.96%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.1972\n",
      "Epoch 6, Validation Loss: 1.2309, Accuracy: 55.62%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.1553\n",
      "Epoch 7, Validation Loss: 1.2136, Accuracy: 56.89%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.0986\n",
      "Epoch 8, Validation Loss: 1.1758, Accuracy: 58.04%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.0419\n",
      "Epoch 9, Validation Loss: 1.1571, Accuracy: 58.30%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.0016\n",
      "Epoch 10, Validation Loss: 1.1997, Accuracy: 57.79%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 0.9697\n",
      "Epoch 11, Validation Loss: 1.0980, Accuracy: 60.67%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.0769\n",
      "Epoch 12, Validation Loss: 1.0936, Accuracy: 60.68%\n",
      "transform: Compose(\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9593\n",
      "Epoch 1, Validation Loss: 1.7372, Accuracy: 33.51%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6806\n",
      "Epoch 2, Validation Loss: 1.6302, Accuracy: 41.17%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5513\n",
      "Epoch 3, Validation Loss: 1.4650, Accuracy: 46.23%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4871\n",
      "Epoch 4, Validation Loss: 1.4021, Accuracy: 49.07%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.4064\n",
      "Epoch 5, Validation Loss: 1.3801, Accuracy: 50.12%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.3715\n",
      "Epoch 6, Validation Loss: 1.3324, Accuracy: 51.98%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.3163\n",
      "Epoch 7, Validation Loss: 1.2997, Accuracy: 52.78%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.2996\n",
      "Epoch 8, Validation Loss: 1.3011, Accuracy: 54.21%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.3143\n",
      "Epoch 9, Validation Loss: 1.2289, Accuracy: 56.14%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2282\n",
      "Epoch 10, Validation Loss: 1.1822, Accuracy: 57.46%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.2068\n",
      "Epoch 11, Validation Loss: 1.1972, Accuracy: 57.30%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 12, Average Loss: 1.2186\n",
      "Epoch 12, Validation Loss: 1.1507, Accuracy: 58.90%\n",
      "transform: Compose(\n",
      "    RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    ToTensor()\n",
      ") test_transform: Compose(\n",
      "    ToTensor()\n",
      ")\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 1, Average Loss: 1.9356\n",
      "Epoch 1, Validation Loss: 1.7266, Accuracy: 35.66%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 2, Average Loss: 1.6469\n",
      "Epoch 2, Validation Loss: 1.5955, Accuracy: 42.16%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 3, Average Loss: 1.5170\n",
      "Epoch 3, Validation Loss: 1.4996, Accuracy: 45.96%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 4, Average Loss: 1.4251\n",
      "Epoch 4, Validation Loss: 1.5054, Accuracy: 47.78%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 5, Average Loss: 1.3449\n",
      "Epoch 5, Validation Loss: 1.3223, Accuracy: 51.53%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 6, Average Loss: 1.2865\n",
      "Epoch 6, Validation Loss: 1.2593, Accuracy: 54.47%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 7, Average Loss: 1.2462\n",
      "Epoch 7, Validation Loss: 1.2168, Accuracy: 56.26%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 8, Average Loss: 1.2332\n",
      "Epoch 8, Validation Loss: 1.2047, Accuracy: 56.54%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 9, Average Loss: 1.1766\n",
      "Epoch 9, Validation Loss: 1.3109, Accuracy: 52.93%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 10, Average Loss: 1.2038\n",
      "Epoch 10, Validation Loss: 1.2254, Accuracy: 55.92%\n",
      "Entered the loop\n",
      "going\n",
      "Epoch 11, Average Loss: 1.1602\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 270, in collate_tensor_fn\n    storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\storage.py\", line 1180, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\storage.py\", line 400, in _new_shared\n    return cls._new_using_filename_cpu(size)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Couldn't open shared file mapping: <torch_2300_2346322430_2594>, error code: <1455>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m      results\u001b[38;5;241m.\u001b[39mappend(model_train(\u001b[38;5;241m0.001\u001b[39m,transforms_list,transforms_test,prepare_model_efficient_net,i))\n",
      "Cell \u001b[1;32mIn[8], line 69\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(lr, transforms_list, test_list, prepare_model, seed)\u001b[0m\n\u001b[0;32m     67\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_Y \u001b[38;5;129;01min\u001b[39;00m data_loader_val:\n\u001b[0;32m     70\u001b[0m         X \u001b[38;5;241m=\u001b[39m batch_X\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m         Y \u001b[38;5;241m=\u001b[39m batch_Y\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1465\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1464\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1491\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 270, in collate_tensor_fn\n    storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\storage.py\", line 1180, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\anaconda\\envs\\torch_envi\\Lib\\site-packages\\torch\\storage.py\", line 400, in _new_shared\n    return cls._new_using_filename_cpu(size)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Couldn't open shared file mapping: <torch_2300_2346322430_2594>, error code: <1455>\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(3):\n",
    "     results.append(model_train(0.001,transforms_list,transforms_test,prepare_model_efficient_net,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca2397-5a96-40fa-ad76-a51167d109dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_resnet(lr):\n",
    "    model = resnext50_32x4d()\n",
    "    model.fc = nn.Linear(2048, num_labels, bias = True)\n",
    "    model.conv1 = nn.Conv2d(3,64, kernel_size = (3,3), stride = 1, padding = 1, bias = False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3a68f-2ca0-4076-bb1a-fd4e3d48c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_resnet = []\n",
    "for i in range(3):\n",
    "     results.append(model_train(0.001,transforms_list,transforms_test,prepare_model_resnet,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "366d1458-173a-48b2-a70a-bd959f760eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[1.896396836435253,\n",
       "    1.5984010344201869,\n",
       "    1.4446623218669132,\n",
       "    1.3392044288868254,\n",
       "    1.2502555649896914,\n",
       "    1.2846737410873175,\n",
       "    1.1660954192788764,\n",
       "    1.1227205916392533,\n",
       "    1.0765761206434532,\n",
       "    1.0802768372337928,\n",
       "    1.0993167562410235,\n",
       "    1.0523471283641728],\n",
       "   [1.9238745688714765,\n",
       "    1.6820514527234165,\n",
       "    1.5477627685124224,\n",
       "    1.4813589987091043,\n",
       "    1.3950765215876428,\n",
       "    1.3410301272842018,\n",
       "    1.3012588913129135,\n",
       "    1.2587992758913473,\n",
       "    1.2426702307367867,\n",
       "    1.2116063188084147,\n",
       "    1.2295753918588161,\n",
       "    1.3419679532843558],\n",
       "   [1.9199579969387164,\n",
       "    1.6549083534628153,\n",
       "    1.5299168178303675,\n",
       "    1.4252659233117646,\n",
       "    1.3347575095566837,\n",
       "    1.2686531329527497,\n",
       "    1.2098984511738473,\n",
       "    1.159646605141461,\n",
       "    1.1191140156747266,\n",
       "    1.098160932348533,\n",
       "    1.0716156600551172,\n",
       "    1.0283333324742587],\n",
       "   [2.0197226880964907,\n",
       "    1.740501982075247,\n",
       "    1.549730440771038,\n",
       "    1.4311655541373924,\n",
       "    1.359321067956361,\n",
       "    1.3115000006827442,\n",
       "    1.2450623337856748,\n",
       "    1.202048703350804,\n",
       "    1.1671822588382796,\n",
       "    1.0941943782805041,\n",
       "    1.0645041669803588,\n",
       "    1.0244080481881446],\n",
       "   [1.9376153915443204,\n",
       "    1.698438664728945,\n",
       "    1.5450000778179278,\n",
       "    1.4828477317298001,\n",
       "    1.3883824341676452,\n",
       "    1.3625218014825473,\n",
       "    1.3123952270570127,\n",
       "    1.2668539676815271,\n",
       "    1.3111890197138896,\n",
       "    1.2677031664008445,\n",
       "    1.1801162141121246,\n",
       "    1.1496058086949317],\n",
       "   [1.9651408339427276,\n",
       "    1.7149448013779791,\n",
       "    1.6033010200004687,\n",
       "    1.516472976146774,\n",
       "    1.4480822089720855,\n",
       "    1.4203448038209567,\n",
       "    1.3549228589981794,\n",
       "    1.3098179195076227,\n",
       "    1.2796021449294956,\n",
       "    1.2408081601289185,\n",
       "    1.2129963392561132,\n",
       "    1.1847239765761928],\n",
       "   [1.9462042725221678,\n",
       "    1.721376487815922,\n",
       "    1.6112507732415742,\n",
       "    1.5380563207648017,\n",
       "    1.4712966035374186,\n",
       "    1.4239333636042746,\n",
       "    1.3754111699421296,\n",
       "    1.3563876307823441,\n",
       "    1.3591050883247093,\n",
       "    1.3053666908632626,\n",
       "    1.2719087815758856,\n",
       "    1.2287752575833688]],\n",
       "  [[28.925555555555555,\n",
       "    41.455555555555556,\n",
       "    47.45111111111111,\n",
       "    51.36222222222222,\n",
       "    54.59444444444445,\n",
       "    53.14111111111111,\n",
       "    57.56333333333333,\n",
       "    59.52222222222222,\n",
       "    61.191111111111105,\n",
       "    61.06222222222222,\n",
       "    60.58222222222223,\n",
       "    62.28111111111111],\n",
       "   [28.587777777777777,\n",
       "    38.36333333333333,\n",
       "    43.346666666666664,\n",
       "    45.602222222222224,\n",
       "    48.967777777777776,\n",
       "    51.019999999999996,\n",
       "    52.77666666666667,\n",
       "    54.16,\n",
       "    54.92111111111111,\n",
       "    56.42,\n",
       "    55.391111111111115,\n",
       "    51.15333333333333],\n",
       "   [27.98111111111111,\n",
       "    39.327777777777776,\n",
       "    44.37222222222223,\n",
       "    48.13333333333333,\n",
       "    51.51444444444444,\n",
       "    54.14444444444444,\n",
       "    56.53111111111111,\n",
       "    58.34222222222222,\n",
       "    59.86,\n",
       "    60.988888888888894,\n",
       "    61.98777777777777,\n",
       "    63.42444444444445],\n",
       "   [24.98777777777778,\n",
       "    35.995555555555555,\n",
       "    43.748888888888885,\n",
       "    48.312222222222225,\n",
       "    51.11111111111111,\n",
       "    53.03888888888889,\n",
       "    55.50333333333334,\n",
       "    56.99333333333333,\n",
       "    58.44444444444444,\n",
       "    61.08444444444444,\n",
       "    62.16222222222222,\n",
       "    63.62777777777778],\n",
       "   [27.582222222222224,\n",
       "    37.56111111111111,\n",
       "    43.41444444444444,\n",
       "    45.77777777777778,\n",
       "    49.49111111111112,\n",
       "    50.592222222222226,\n",
       "    52.452222222222225,\n",
       "    54.10111111111111,\n",
       "    52.690000000000005,\n",
       "    54.178888888888885,\n",
       "    57.538888888888884,\n",
       "    58.81222222222222],\n",
       "   [26.884444444444444,\n",
       "    36.34444444444445,\n",
       "    41.17666666666667,\n",
       "    44.70444444444445,\n",
       "    47.49666666666666,\n",
       "    48.559999999999995,\n",
       "    51.14777777777778,\n",
       "    52.65,\n",
       "    53.71666666666667,\n",
       "    55.25666666666667,\n",
       "    56.37333333333333,\n",
       "    57.43888888888888],\n",
       "   [27.485555555555557,\n",
       "    36.467777777777776,\n",
       "    40.83444444444444,\n",
       "    43.55222222222222,\n",
       "    46.364444444444445,\n",
       "    47.967777777777776,\n",
       "    49.87888888888889,\n",
       "    50.7988888888889,\n",
       "    50.644444444444446,\n",
       "    52.50666666666667,\n",
       "    54.06999999999999,\n",
       "    55.54333333333334]],\n",
       "  [[1.7582565525716,\n",
       "    1.4898140215399591,\n",
       "    1.4325477445328778,\n",
       "    1.3124373937872322,\n",
       "    1.4697639283470132,\n",
       "    1.2562347291545435,\n",
       "    1.198049275289205,\n",
       "    1.161290788684379,\n",
       "    1.1643869027664715,\n",
       "    1.130526982332495,\n",
       "    1.1271639033644036,\n",
       "    1.374859324910424],\n",
       "   [1.7645321036265655,\n",
       "    1.6900987472723832,\n",
       "    1.4498996306210756,\n",
       "    1.3711348316547545,\n",
       "    1.3332974768497727,\n",
       "    1.278648280961947,\n",
       "    1.3943262189965357,\n",
       "    1.212633803232827,\n",
       "    1.1829045987264677,\n",
       "    1.1651631209321998,\n",
       "    1.1363390646028249,\n",
       "    1.2143522331660443],\n",
       "   [1.8947135850109837,\n",
       "    1.7333797023377635,\n",
       "    1.5537800739773295,\n",
       "    1.6131913590837608,\n",
       "    1.2921969638290731,\n",
       "    1.2410477544604377,\n",
       "    1.2413083397021347,\n",
       "    1.1634817578067833,\n",
       "    1.1406403938308358,\n",
       "    1.10182838302783,\n",
       "    1.0827503804625436,\n",
       "    1.0386183393949813],\n",
       "   [2.049329903315414,\n",
       "    1.6136734340001235,\n",
       "    1.5219844664362343,\n",
       "    1.9143810292536563,\n",
       "    1.3689895847981626,\n",
       "    1.4461661721156402,\n",
       "    1.4379523526877165,\n",
       "    1.5420548060739583,\n",
       "    1.2397313061254946,\n",
       "    1.2240140985020183,\n",
       "    1.3024850448762828,\n",
       "    1.1884696724909274],\n",
       "   [1.7860971784049815,\n",
       "    1.5985891559923238,\n",
       "    1.4777156158604405,\n",
       "    1.4071602582592855,\n",
       "    1.2938661058856682,\n",
       "    1.3661598747765475,\n",
       "    1.3065847280350598,\n",
       "    1.240992267108099,\n",
       "    1.1845860670913348,\n",
       "    1.1593062506819314,\n",
       "    1.1523667426610535,\n",
       "    1.0844909581779079],\n",
       "   [1.7710083089768887,\n",
       "    1.6039912505921992,\n",
       "    1.5266481531275944,\n",
       "    1.4276544295928695,\n",
       "    1.3277925992892547,\n",
       "    1.3169926118782975,\n",
       "    1.2715332799337127,\n",
       "    1.2850213912738995,\n",
       "    1.2292340289462695,\n",
       "    1.1644877568733962,\n",
       "    1.1355318381366404,\n",
       "    1.323420100168071],\n",
       "   [1.7699152669784697,\n",
       "    1.5874532237648964,\n",
       "    1.5306190220131115,\n",
       "    1.485629996962168,\n",
       "    1.4138110158118335,\n",
       "    1.4219748933206906,\n",
       "    1.2837739099155774,\n",
       "    1.36059524203566,\n",
       "    1.2682656829499386,\n",
       "    1.2183982327749783,\n",
       "    1.1690307584675876,\n",
       "    1.1846679592166434]],\n",
       "  [[36.44,\n",
       "    45.37,\n",
       "    47.84777777777778,\n",
       "    52.65555555555556,\n",
       "    47.09777777777778,\n",
       "    55.04555555555556,\n",
       "    56.718888888888884,\n",
       "    58.01444444444444,\n",
       "    58.06888888888889,\n",
       "    59.63222222222222,\n",
       "    59.648888888888884,\n",
       "    50.81888888888889],\n",
       "   [36.346666666666664,\n",
       "    42.038888888888884,\n",
       "    46.95111111111111,\n",
       "    49.70444444444445,\n",
       "    51.25555555555555,\n",
       "    53.351111111111116,\n",
       "    51.60555555555556,\n",
       "    55.53666666666667,\n",
       "    57.51666666666667,\n",
       "    58.10444444444445,\n",
       "    59.33888888888889,\n",
       "    56.04333333333334],\n",
       "   [33.86111111111111,\n",
       "    41.80888888888889,\n",
       "    46.26,\n",
       "    48.14333333333333,\n",
       "    53.31333333333333,\n",
       "    55.70111111111111,\n",
       "    56.053333333333335,\n",
       "    58.51888888888889,\n",
       "    59.25666666666667,\n",
       "    61.17777777777778,\n",
       "    61.72666666666666,\n",
       "    63.184444444444445],\n",
       "   [29.45111111111111,\n",
       "    40.83555555555556,\n",
       "    44.763333333333335,\n",
       "    33.068888888888885,\n",
       "    50.76555555555555,\n",
       "    48.14555555555556,\n",
       "    49.02,\n",
       "    43.05444444444444,\n",
       "    55.82888888888888,\n",
       "    56.62777777777778,\n",
       "    53.97,\n",
       "    57.730000000000004],\n",
       "   [32.83555555555556,\n",
       "    42.906666666666666,\n",
       "    45.705555555555556,\n",
       "    48.70666666666666,\n",
       "    53.17666666666667,\n",
       "    50.51777777777777,\n",
       "    52.336666666666666,\n",
       "    55.45444444444444,\n",
       "    57.504444444444445,\n",
       "    58.3811111111111,\n",
       "    58.556666666666665,\n",
       "    61.15555555555555],\n",
       "   [33.27111111111111,\n",
       "    42.10333333333333,\n",
       "    43.669999999999995,\n",
       "    48.06777777777778,\n",
       "    51.47888888888888,\n",
       "    52.918888888888894,\n",
       "    53.97888888888889,\n",
       "    53.712222222222216,\n",
       "    55.66888888888889,\n",
       "    58.025555555555556,\n",
       "    59.20444444444445,\n",
       "    55.403333333333336],\n",
       "   [34.181111111111115,\n",
       "    41.28333333333333,\n",
       "    44.336666666666666,\n",
       "    46.28111111111111,\n",
       "    49.11888888888889,\n",
       "    50.621111111111105,\n",
       "    53.25888888888889,\n",
       "    52.42555555555556,\n",
       "    53.71555555555556,\n",
       "    56.235555555555564,\n",
       "    57.79333333333333,\n",
       "    58.28111111111111]]),\n",
       " ([[1.9029125156389042,\n",
       "    1.6160081911154769,\n",
       "    1.4550291311673142,\n",
       "    1.3514123431999574,\n",
       "    1.2668104964223774,\n",
       "    1.2101388875903054,\n",
       "    1.1541284995830872,\n",
       "    1.1024725944311782,\n",
       "    1.0412954057312824,\n",
       "    1.0031208061528476,\n",
       "    0.965295550328764,\n",
       "    0.928055983460085],\n",
       "   [1.9469473404301838,\n",
       "    1.6897092310881072,\n",
       "    1.6070211575451223,\n",
       "    1.519255655394359,\n",
       "    1.4456531559540466,\n",
       "    1.4000263269990683,\n",
       "    1.3961168471723795,\n",
       "    1.3939580079168081,\n",
       "    1.3176725339144468,\n",
       "    1.2678856885229999,\n",
       "    1.2718506921082735,\n",
       "    1.3346511658958413],\n",
       "   [1.8877425302158704,\n",
       "    1.6063816657459193,\n",
       "    1.4875660936602138,\n",
       "    1.401465086943724,\n",
       "    1.3265621083026582,\n",
       "    1.2669530698860234,\n",
       "    1.2204000531611117,\n",
       "    1.3058650876310738,\n",
       "    1.171353694644164,\n",
       "    1.1279916238378396,\n",
       "    1.0897707307541913,\n",
       "    1.0571918794038622],\n",
       "   [2.028167753734372,\n",
       "    1.703972682695497,\n",
       "    1.531847278333523,\n",
       "    1.3972672913223505,\n",
       "    1.3148319963365793,\n",
       "    1.2429512420838529,\n",
       "    1.192355365069075,\n",
       "    1.1452663750811056,\n",
       "    1.0960075535218825,\n",
       "    1.0717751379548148,\n",
       "    1.022126201201569,\n",
       "    1.0143194123255936],\n",
       "   [1.9448533198711546,\n",
       "    1.687105973505161,\n",
       "    1.5541273711079902,\n",
       "    1.4574996346438474,\n",
       "    1.384601255370812,\n",
       "    1.3294457688250325,\n",
       "    1.2726178082891486,\n",
       "    1.2710360761901194,\n",
       "    1.2265981631353498,\n",
       "    1.1727943108840422,\n",
       "    1.1763091752813621,\n",
       "    1.1428600484505296],\n",
       "   [2.0060197760097007,\n",
       "    1.7711292896419764,\n",
       "    1.6480316462164575,\n",
       "    1.5981225325641306,\n",
       "    1.5136302878910846,\n",
       "    1.4603358419104056,\n",
       "    1.4033420033414254,\n",
       "    1.364515609023246,\n",
       "    1.3213733287358826,\n",
       "    1.2801146566529165,\n",
       "    1.252360757101666,\n",
       "    1.228593094443733],\n",
       "   [1.9377492735670372,\n",
       "    1.6960398019714789,\n",
       "    1.6070101340724663,\n",
       "    1.5262540827759288,\n",
       "    1.459199719638987,\n",
       "    1.4559007266705686,\n",
       "    1.387112114409154,\n",
       "    1.3393883293663913,\n",
       "    1.3194527096030386,\n",
       "    1.2860648291693493,\n",
       "    1.264360433105718,\n",
       "    1.23142760111527]],\n",
       "  [[28.89888888888889,\n",
       "    40.346666666666664,\n",
       "    47.03666666666667,\n",
       "    50.89666666666667,\n",
       "    54.245555555555555,\n",
       "    56.20333333333334,\n",
       "    58.51,\n",
       "    60.43777777777778,\n",
       "    62.87222222222222,\n",
       "    64.3311111111111,\n",
       "    65.63,\n",
       "    67.07111111111111],\n",
       "   [27.346666666666668,\n",
       "    37.36333333333333,\n",
       "    40.88666666666666,\n",
       "    44.14222222222222,\n",
       "    47.22666666666667,\n",
       "    48.88222222222222,\n",
       "    49.31333333333333,\n",
       "    49.230000000000004,\n",
       "    52.178888888888885,\n",
       "    54.07555555555555,\n",
       "    54.23777777777777,\n",
       "    51.66555555555556],\n",
       "   [29.351111111111113,\n",
       "    41.047777777777775,\n",
       "    45.74777777777778,\n",
       "    48.99333333333333,\n",
       "    51.68888888888888,\n",
       "    54.02666666666667,\n",
       "    55.913333333333334,\n",
       "    52.53666666666666,\n",
       "    57.59333333333333,\n",
       "    59.34555555555555,\n",
       "    61.04333333333334,\n",
       "    62.13666666666666],\n",
       "   [25.694444444444443,\n",
       "    37.9,\n",
       "    44.504444444444445,\n",
       "    49.68888888888889,\n",
       "    52.91444444444444,\n",
       "    55.59222222222222,\n",
       "    57.64666666666667,\n",
       "    59.492222222222225,\n",
       "    61.03777777777778,\n",
       "    62.05888888888889,\n",
       "    63.70666666666666,\n",
       "    63.98888888888889],\n",
       "   [27.46,\n",
       "    37.51444444444444,\n",
       "    43.19222222222222,\n",
       "    46.89666666666666,\n",
       "    49.82333333333333,\n",
       "    52.0,\n",
       "    54.15555555555556,\n",
       "    54.12555555555556,\n",
       "    55.87555555555556,\n",
       "    57.977777777777774,\n",
       "    57.87,\n",
       "    59.12111111111111],\n",
       "   [25.11,\n",
       "    34.11888888888889,\n",
       "    39.36222222222222,\n",
       "    41.58555555555555,\n",
       "    44.66555555555555,\n",
       "    46.60444444444444,\n",
       "    48.96111111111111,\n",
       "    50.11444444444444,\n",
       "    51.946666666666665,\n",
       "    53.55333333333333,\n",
       "    54.88666666666666,\n",
       "    55.75],\n",
       "   [27.324444444444445,\n",
       "    37.02111111111111,\n",
       "    40.99666666666666,\n",
       "    44.09222222222222,\n",
       "    46.79,\n",
       "    47.16111111111111,\n",
       "    49.40777777777778,\n",
       "    51.24444444444445,\n",
       "    51.998888888888885,\n",
       "    53.65888888888889,\n",
       "    54.47555555555555,\n",
       "    55.43333333333334]],\n",
       "  [[1.739557828076861,\n",
       "    1.5445075692100958,\n",
       "    1.511095880446109,\n",
       "    1.3574172845956953,\n",
       "    1.317041534253142,\n",
       "    1.259886889718473,\n",
       "    1.29590558599342,\n",
       "    1.1521560052748432,\n",
       "    1.1382523092695258,\n",
       "    1.1360199920494447,\n",
       "    1.086541687053713,\n",
       "    1.1179858960041946],\n",
       "   [1.9132016748189926,\n",
       "    1.6119413960047744,\n",
       "    1.5754290693862871,\n",
       "    1.474138938059861,\n",
       "    1.3906146506355568,\n",
       "    1.3514003990726038,\n",
       "    1.3432132964107124,\n",
       "    1.2626217254860834,\n",
       "    1.2843119872903281,\n",
       "    1.2154668877747925,\n",
       "    1.2605064966800539,\n",
       "    1.4001704960722814],\n",
       "   [1.6856520616195418,\n",
       "    1.5501692457632585,\n",
       "    1.4800566368820993,\n",
       "    1.3885327572511001,\n",
       "    1.3808606170456519,\n",
       "    1.2233104481446473,\n",
       "    1.5431547466326843,\n",
       "    1.238515161655166,\n",
       "    1.2021013459360057,\n",
       "    1.1135145877911286,\n",
       "    1.1010905846276067,\n",
       "    1.0887029722163624],\n",
       "   [1.8339875320141965,\n",
       "    1.6463113454255192,\n",
       "    1.520897918634794,\n",
       "    1.4157628305256367,\n",
       "    1.3794271673329852,\n",
       "    1.350108628076586,\n",
       "    1.3598693695596673,\n",
       "    1.2412604624405503,\n",
       "    1.2790951907465404,\n",
       "    1.1936569516970352,\n",
       "    1.2539014579220251,\n",
       "    1.1756935751234943],\n",
       "   [2.071905717761679,\n",
       "    1.6065568608993834,\n",
       "    1.6225399532440035,\n",
       "    1.4642259928990493,\n",
       "    1.3116921191527084,\n",
       "    1.234864140945402,\n",
       "    1.243137538687072,\n",
       "    1.219710174947977,\n",
       "    1.2735966442322189,\n",
       "    1.1266644161025232,\n",
       "    1.1673877695575356,\n",
       "    1.0932729820805518],\n",
       "   [1.8236598257314076,\n",
       "    1.7548851399597796,\n",
       "    1.5556414735249497,\n",
       "    1.5094585853882811,\n",
       "    1.4935798900709911,\n",
       "    1.3274462519382888,\n",
       "    1.3418657002462582,\n",
       "    1.2875539707866581,\n",
       "    1.2621733794327488,\n",
       "    1.1931048375131055,\n",
       "    1.174797791056335,\n",
       "    1.1839793078940024],\n",
       "   [1.7828341405838728,\n",
       "    1.6054450639269569,\n",
       "    1.4842104063454,\n",
       "    1.5616562407125125,\n",
       "    1.3719027010215954,\n",
       "    1.429178497330709,\n",
       "    1.3075192582539537,\n",
       "    1.3352464346892454,\n",
       "    1.3264539888636633,\n",
       "    1.2889566805891015,\n",
       "    1.195235331796787,\n",
       "    1.165314150550826]],\n",
       "  [[35.92333333333333,\n",
       "    43.333333333333336,\n",
       "    47.36333333333334,\n",
       "    50.690000000000005,\n",
       "    52.21111111111111,\n",
       "    53.79333333333334,\n",
       "    52.733333333333334,\n",
       "    58.50222222222222,\n",
       "    58.96111111111111,\n",
       "    59.27111111111111,\n",
       "    61.06,\n",
       "    60.142222222222216],\n",
       "   [32.126666666666665,\n",
       "    40.318888888888885,\n",
       "    41.848888888888894,\n",
       "    46.025555555555556,\n",
       "    48.91666666666667,\n",
       "    51.31,\n",
       "    50.853333333333325,\n",
       "    54.16111111111112,\n",
       "    53.398888888888884,\n",
       "    56.35,\n",
       "    54.87,\n",
       "    49.70777777777778],\n",
       "   [37.48555555555556,\n",
       "    43.40111111111111,\n",
       "    46.86222222222222,\n",
       "    49.12111111111111,\n",
       "    52.82333333333333,\n",
       "    55.769999999999996,\n",
       "    45.30444444444445,\n",
       "    55.507777777777775,\n",
       "    56.98,\n",
       "    60.17111111111111,\n",
       "    60.605555555555554,\n",
       "    61.081111111111106],\n",
       "   [31.99111111111111,\n",
       "    39.70333333333333,\n",
       "    44.81222222222222,\n",
       "    48.83777777777778,\n",
       "    50.38111111111111,\n",
       "    51.94222222222222,\n",
       "    51.64,\n",
       "    55.784444444444446,\n",
       "    54.836666666666666,\n",
       "    57.757777777777775,\n",
       "    56.34,\n",
       "    58.75555555555556],\n",
       "   [34.94111111111111,\n",
       "    42.352222222222224,\n",
       "    41.967777777777776,\n",
       "    48.27666666666667,\n",
       "    52.52111111111111,\n",
       "    55.934444444444445,\n",
       "    55.69666666666667,\n",
       "    55.735555555555564,\n",
       "    57.60444444444445,\n",
       "    59.885555555555555,\n",
       "    58.044444444444444,\n",
       "    60.99],\n",
       "   [31.182222222222222,\n",
       "    35.36222222222222,\n",
       "    41.86111111111111,\n",
       "    44.275555555555556,\n",
       "    45.711111111111116,\n",
       "    51.78111111111111,\n",
       "    50.65666666666667,\n",
       "    52.92,\n",
       "    53.73,\n",
       "    57.18222222222222,\n",
       "    57.608888888888885,\n",
       "    57.56444444444444],\n",
       "   [34.36666666666667,\n",
       "    40.88444444444445,\n",
       "    45.97555555555555,\n",
       "    45.17666666666666,\n",
       "    49.903333333333336,\n",
       "    49.66888888888889,\n",
       "    52.23222222222223,\n",
       "    51.84444444444445,\n",
       "    52.26666666666666,\n",
       "    53.404444444444444,\n",
       "    57.056666666666665,\n",
       "    57.97666666666667]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bdaae-2915-4f3a-be1e-598905bab44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
